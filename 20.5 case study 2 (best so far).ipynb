{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised and simplified version of cs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what else can be done or any question\n",
    "#normalize the x? before training\n",
    "#how to undo normalized in normalization\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change name column to lowercase is easier to proceed\n",
    "\n",
    "# Make column labels lowercase\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# Replace spaces in columns with underscore\n",
    "df.columns = df.columns.str.replace('\\s+', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows and columns\n",
    "print('Data: \\n')\n",
    "print(\"Number of columns: \"+ str(df.shape[1]))\n",
    "print(\"Number of rows: \"+ str(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(),annot=True,cmap='YlGnBu',fmt='.2f',linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['age'],color='Red',hist_kws={'alpha':1,\"linewidth\": 2}, kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check outlier\n",
    "#1.iqr\n",
    "#2.zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using zscore to detect outliers\n",
    "#good god im lazy...im using zscore because its looks easier to do\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(df))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df['thal']==0]\n",
    "\n",
    "df1['thal'] = df['thal'].replace(0,2)\n",
    "\n",
    "df1['thal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some of the features are categorical...\n",
    "#sex,cp,fbs,restecg,exang,slope,ca,thal,target\n",
    "#double check this with the definition documents\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sex']=df1['sex'].astype('category')\n",
    "df1['cp']=df1['cp'].astype('category')\n",
    "df1['fbs']=df1['fbs'].astype('category')\n",
    "df1['restecg']=df1['restecg'].astype('category')\n",
    "df1['exang']=df1['exang'].astype('category')\n",
    "df1['slope']=df1['slope'].astype('category')\n",
    "df1['ca']=df1['ca'].astype('category')\n",
    "df1['thal']=df1['thal'].astype('category')\n",
    "df1['target']=df1['target'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#one hot encoding \n",
    "#use this for those categorical datatype..rmmbr to remove first dupe\n",
    "\n",
    "df1=pd.get_dummies(df1,drop_first=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,plot_confusion_matrix\n",
    "from joblib import dump\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.drop('target',axis=1)\n",
    "y = df1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model= LogisticRegression(solver='saga',multi_class=\"ovr\",max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penalty\n",
    "penalty= ['l1']\n",
    "\n",
    "#use logarithmic spaced c values\n",
    "C = [1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model=GridSearchCV(log_model,param_grid={'C':C,'penalty':penalty})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =best_model.coef_\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =grid_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the scaler and model for deployment\n",
    "dump(scaler,\"casestudy2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump(grid_model,\"casestudy2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "heart_model = load(\"casestudy2.h5\")\n",
    "\n",
    "heart_scaler = load(\"casestudy2.pkl\")\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    age = sample_json['age']\n",
    "    sex = sample_json['sex']\n",
    "    cp = sample_json['cp']\n",
    "    trestbps = sample_json['trestbps']\n",
    "    chol = sample_json['chol']\n",
    "    fbs = sample_json['fbs']\n",
    "    restecg = sample_json['restecg']\n",
    "    thalach = sample_json['thalach']\n",
    "    exang = sample_json['exang']\n",
    "    oldpeak = sample_json['oldpeak']\n",
    "    slope = sample_json['slope']\n",
    "    ca = sample_json['ca']\n",
    "    thal = sample_json['thal']\n",
    "    \n",
    "    heart = [[age,sex,cp,trestbps,chol,fbs,restecg,thalach,\n",
    "       exang,oldpeak,slope,ca,thal]]\n",
    "    \n",
    "    heart = scaler.transform(heart)\n",
    "    \n",
    "    prediction= model.predict(heart)\n",
    "\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_pred = {'age':63,\n",
    "              'sex':1,\n",
    "              'cp':3,\n",
    "              'trestbps':145,\n",
    "              'chol':233,\n",
    "              'fbs':1,\n",
    "              'restecg':0,\n",
    "              'thalach':150,\n",
    "              'exang':0,\n",
    "              'oldpeak':2.3,\n",
    "              'slope':0,\n",
    "              'ca':0,\n",
    "              'thal':1}             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = return_prediction(heart_model,heart_scaler,heart_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
